\section{Manipulation and Control of the Environment}

To provide a convenient tool for people with severe injuries, who cannot carry out everyday tasks using their hands, manipulation and control of the environment has became a popular research topic in the field of assistive technologies. Aside from traditional means, such as joysticks and modified switches, that need a certain level of physical movement ability in the users' hands and fingers, to address this need, two important applications stand out among the others; tongue drive systems and eye-trackers.
%for disabled people without functioning fingers and hands. 

These applications have a wide range of users with high level physical disabilities, such as those with high-level spinal injury, upper limb amputation, amyotrophic lateral sclerosis (ALS), and certain types of stroke. The common characteristics of these applications are that they all use sensors to infer the user intentions from their remaining volitional movement abilities, not in their hands and fingers but and exploit the movements of the tongue and eyes to stimulate the behaviors of fingers and hands.

\subsection{Tongue Drive System}
Mouth and particularly the tongue are inherently capable of sophisticated motor control and high-resolution manipulation tasks with many degrees of freedom thanks to the myriad of sensory and motor neurons that represent them in the human brain. A tongue-computer interface called Tongue Drive System (TDS) was introduced by (Jia Wang et al., 2008) in 2008. The proposed TDS takes advantage of tongues' dexterity and its direct  connections with the brain through the hypoglossal nerve. TDS is envisioned to help people with severe disabilities to conduct their daily activities, including computer/smartphone access, control of the wheelchair and motorized bed. Although promising, the success of a TDS relies on the accuracy of tongue motion tracking. Therefore, the precise localization of the tongue appears to be one of the main research topics for TDS. Magnetic, inductive, and optical sensors have found usage in recent research on localization and tracking of the tongue movements. In the following we elaborate on the use of sensors in some variations of the TDS.

(Sahadat et al., 2018) proposed a multi-modal tongue drive system (mTDS) that deployed magnetic sensors to emulate mouse cursor clicks  by monitoring the tongue movements. Magnetic sensors measuring magnetic field density are used to estimate the location of a permanent magnetic tracer through the mathematical formula mentioned in (Sebkhi et al., 2018). Thus, the raw data from magnetic sensors is processed in real time to track the tongue movements wirelessly with millimeter resolution while maintaining safe use inside the oral cavity without impeding the tongue's natural motion. The system integrates an array of two modules, each of them housing two magnetic sensors, for the measurement of magnetic field density with high accuracy. The tongue's left movement represent a "left click" and right movement represent a "right click". Furthermore, the researchers run an experiment with fifteen healthy subjects. Subjects performed an email typing task with random content via the mTDS versus a keyboard and a mouse. The task included mouse clicking command, and all the subjects could click correctly by using their tongues via the mTDS.

%insert the TDS pictures Magnetic_TDS, Inductive_TDS, Optical_TDS.


Another study (Struijk et al., 2017) utilizes inductive sensors in a tongue-computer interface (TCI) designed for individuals with tetraplegia, which indicates paralysis in all four limbs and torso. The inductive sensors used in the interface design are composed of an array of air-cored inductors. Based on Faraday's law, when a small ferromagnetic tracer that is attached to the tongue is placed at the center of an inductor, the  relative magnetic permeability of the coil increases. Accordingly, the voltage drop across the inductor will increase and maintain that value until the tracer is removed. Relying on this principle, the system scans the inductors and detects the tongue position based on the inductor, which value is changed, and transmits the sensor data through radio to a PC or any other target device. The TCI designed with 18 inductive sensors is placed in the oral cavity. Ten of these sensors construct a 10-key pad, and the rest form the mouse/joystick pad. The TCI embedded the sensor array PCB, a control unit and a battery under user's tongue. The study also presents experimental results that are conducted with two tetraplegic and two able-bodied individuals, who wore the proposed TCI. The maximum typing rates are recorded as 1.8 and 1.4 seconds for repetitive typing of a correct character on the keypad and the mouse pad area, respectively. 


Previous examples were assistive technologies that require a tracer attached to the user's tongue. An example of a tracer-free approach tracks tongue movement based on glossokinetic potentials (GKP), which are potential alterations in electroencephalography (EEG) signals when the tongue touches the side of the cheeks (Nam et al., 2016). GKP used to be described as a signal artifact that should be removed during the preprocessing stage of the EEG signals. In 2012, (Attarian et al., 2012) discovered the relationship between tongue movements and GKP levels. The authors describe the change in GKP levels with the direction of the tongue movement;  when the tongue moves to one side, GKP levels on that side decrease, and vice versa on the other side. The tongue-machine interface (TMI) proposed in this study translates GKP levels into the horizontal position of the tongue with a linear model. EEG electrodes are used to monitor GKP levels changes. The experiment is performed with four subjects. Based on four subjects' 90 random angle cues from $- 90^{\circ}$ to $+ 90^{\circ}$, the TMI's detection mean value of angle is $18.9^{\circ}$. This value is sufficient to control a wheelchair to change the direction angle. The usability of GKP levels is demonstrated and an application to control the direction of powered wheelchair is presented too. %Further research on this topic is going to improve the sensitivity and implement this system on other complicated manipulation tasks. 

Another tracer-free TDS is implemented with four optical distance sensors and one ambient light sensor in (Jiang et al., 2020). While four optical distance sensors over the user's upper jaw detect any contacts with the tongue, the ambient light sensor on the retainer's frontal surface  indicates whether the mouth is closed. This system also includes a sensor data fusion algorithm to eliminate unintended tongue contacts with sensors. The experiments involve eleven healthy individuals to test the discrimination of unintended tongue contacts with new sensor setup and masking ability of the data fusion algorithm. The accuracy of mouth cursor commands on a computer was also tested. The experiment results revealed that the fusion algorithm could mask 86.99\% unintended tongue contacts during swallowing, while the proposed system achieved 97.16±0.94\% accuracy during the random mouth cursor commands test. %This paper presents a functioning tracer-free TDS by using optical sensor with sensor data fusion algorithm to avoid unintended touch.



\subsection{Eye-trackers}
Eye-tracking is the mechanism behind another group of assistive technologies that offer accurate control commands to people with severe disability without requiring any physical interaction. Similar to tongue movements, voluntary eye blinking and movements can be used as a control method for those with a wide range of injuries and diseases ranging from high-level paralysis to progressive diseases like Amyotrophic Laternal Sclerosis (ALS). In the past two decades, many studies have been conducted on eye-trackers and eye-computer interfaces (ECI) that control expansive applications, such as wheelchair, smart home, and office tools. There are even commercial eye-tracking systems available in the market for assistive technology as well as research on the eye motion and evaluating user response to the arrangement of scenes, web pages, advertisement, etc. Tobii series, SR Research and SMI RED250. The following paragraphs will cover several popular eye-trackers based on electrooculography (EOG), infrared camera, microwave resonator and inductive sensors. 

%insert the ET pictures EEG_Wearing, Inductive_Eye 

% EOG Sensory 
Sensory EOG is a method that measures the corneo-retinal standing potential to map the eye's position. A pair of EOG electrodes are placed on the face closed to eyes. When the eye moves towards one electrode, and far from the other one, the corneo-retinal standing potential develops.  Once recorded, post-processing technics can translate these signals into eye movements. A successful implementation of EOG is demonstrated in (Zhang, 2018). In that study, researchers developed an EOG-based human-computer interface (HCI) that controls smart home equipment to help people with severe spinal cord injury. The user sent the control command by blinking an eye towards the corresponding flashing button. While the sensory electrode was placed above the user's left eyebrow, the reference electrode was placed on the forehead. The authors implemented a graphical user interface (GUI) with multiple buttons that control various smart home equipment and a detection algorithm that captures the user's control-purposed blinks. This online experiment included seven subjects with spinal cord injury (SCI), who were asked to use this HCI to control house-hold devices, such as electrical appliances, a wheelchair, and a nursing bed. The experiment results showed 4.1\% average false operation ratio in the control state and non-false operations in the idle state. The proposed system can also be tested and optimized on those in different SCI states and on subjects with other severe diseases and injuries. 

% IR Camera
Captured by an infrared camera, images of eyes can reveal the gaze directions, which then can be used by people with diseases or injuries related to motor disabilities to control assistive technology applications, including wheelchair and nursing bed. (Dahmani, 2020) proposes an eye-tracking system for wheelchair control based on an infrared camera. This eye-tracking system requires the user to wear a head-mounted device integrating with two infrared cameras to capture the eye's images for gaze estimation and an array of ultrasound sensors for the wheelchair emergency stop. The infrared camera was a select type of camera used in this system. It could provide constant images in environments with various brightness, and infrared emitting light won't affect the user. To process the eye's images, the authors use the Convolutional Neural Network (CNN) to classify various gaze direction types with high accuracy and processing speed. The team collected 3200 images of eyes from 8 individuals to evaluate this system's gaze estimation accuracy and speed. After five-fold cross-validation based on 20\% of 3200 images, the overall accuracy of the CNN classification is 99.3\%  with a 1.53 ms duration of time to predict the gaze direction. On top of the available three directions, which are plus stop movements in the current system, a further study can provide more degrees of freedom. Another interesting addition can be inviting subjects with motor disability diseases to test the accuracy of the proposed eye-tracking system in wheelchair control experiments. 

%Microwave sensory
Microwave sensing provides a gaze detection method without contact, and this method was implemented in the article (Lee. 2019). The researchers designed a wearable eye-tracker integrating two open complementary split-ring resonators (OCSRR) sensors. The gaze point is captured by the pupil and the eyelid, which are the results of perturbations in the planar resonator's electrical field distribution. The eye-tracker was formed with a pair of wearable eyeglasses and two of the OCSRR sensors were placed at the corner of the eyeglass temple and eyeglass lens on both sides. The research group also did a human experiment with four subjects to verify the accuracy of both horizontal and vertical eye tracking via this device. The subjects were required to wear the eye-tracker and pay attention to the target points on a 2-D eye-tracker map. For horizontal eye tracking, the average accuracy was 2.81 degree and for vertical tracking was 3.56 degree. The researches planed to implement this OCSRR sensor to VR, AR and other eye-tracking needed applications.

% Inductive Eye Tracker 
The eyelid drive system (EDS) is a method that uses inductive sensing to detect eye movements and blinks (Graybill, 2018). EDS sensing parts include a pair of glasses with embedded coils, and a pair of passive resonators stuck on the user's eyelids. The embedded coils and a resonator create a 3-coil inductive link on both sides of the glasses. When the user blinks an eye, the coupling change in these inductive links generates measurable signals to detect the eye's blinks. After the amplification, digitization, and post-processing of the signals, the MCU attached to the glasses transmits control commands to the PC wirelessly. The command set includes L, LL, LR, LB, R, RL, RR, and RB, in which L, R, and B stand for left and right winks, and a blink, respectively.Six subjects participated in human experiments to test EDS command accuracy and response time,  a series of response tests with various commands, and corresponding tests. For PC access, the test protocol required subjects to use the 8 commands via EDS to navigate a cursor in a maze created by LabVIEW GUI. For the test of four commands with three seconds response time, the mean accuracy was at its highest, 96.3\%. A mean information transfer rate was 56.1 b/min for the test of six commands with 1.5 seconds response time. All the participants were able to finish the maze game. To carry further this research, measuring the duration time of blink and wink could help to develop proportional control via EDS.



\subsection{Sensors in Use}
This section will highlight sensors that are distinct to the manipulation and control of the environment.

\subsubsection{Magnetic Sensor}
Magnetic sensors is used to measure the magnetic flux density of the environment without contact. By implement an array of magnetic sensors with know position, it is possible to use the direction of an applied magnetic field to estimate the position of the magnetic field source. Researchers distributed 4 magnetic sensors to 2 sensor arrays and fixed those arrays on two sides of the headset's sensor arms in (Sahasdat et al., 2018). The magnetic sensor used by the team was LSM303D 3-axial magnetometers (STMicroelectronics). The sensor has selectable magnetic field dynamic ranges of ±2 / ±4 / ±8 / ±12 gauss with maximum 100Hz sampling rate. For this application, ±4 dynamic range was selected with a resolution of 0.16 mgauss/LSB.

\subsubsection{Inductive Sensor}
Inductive sensors used for TDS applications monitor the voltage drop across the sensor. In (Struijk et al., 2017), the intraoral inductive sensor array was positioned under the tongue. The sensor array was created by 18 air-cored induction coils, manufactured on a ten-layer PCB with 1mm thickness. In each PCB layer, ten-turn coils were printed for every inductor. The connection between each of two layers was plated through holes. Thus, the outer diameter of each inductor is 6.2 mm, and the inner diameter is 4.3 mm with a total of 100 turns. 

Inductive sensors can also be deployed in eye-tracker applications. In (Graybill, 2018), three inductive coils were used to form a three-coil link for inductive sensing. The frequency of the link was 16.368 MHz. The coil's turns embedded on the left glass and the right glass were one and three, respectively, 3 with wire diameter 0.404 mm. The coil's turns attached to the user's eyelids are 9 with a diameter of 0.079mm.

\subsubsection{Optical Sensor}
Optical distance measurement sensors detect the contacts between the tongue and sensors, and an ambient optical sensor detects the mouth's openness in tracer-free TDS application.  (Jiang et al., 2020) used four optical distancing sensors and one ambient sensor in their TDS. The researchers chose four GP2S700HCP (Sharp Microelectronics, WA) as the optical distancing sensors with a 3 mm sensing distance and a 950 nm maximum sensitivity wavelength. The distance sensors were placed on the upper palatal surface. The selected optical ambient sensor is APDS-9006-020. The ambient sensor is attached between the two front teeth towards the tongue.

%new
%% Add EEG electrode, talk about active and passive types.

\subsubsection{EEG Electrodes}

\subsubsection{EOG eye-tracker}

\subsubsection{Microwave Resonator}

\subsubsection{IR Camera}

