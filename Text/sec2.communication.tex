\section{Augmentative and Assistive Communication Systems}

Augmentative and Assistive Communication (AAC) Systems aim to provide a means of communication not only for the people with severe language disorders but also for people with normal speech but with other disabilities. By recognizing and conveying the users' conversations, needs, and intentions, AACs assist such users in their daily life. Voice recognition and language disorder restoration are two other potential applications of AAC. For example, people who have a laryngectomy operation, i.e. have their larynx removed from the esophagus (ref:wikipedia) can benefit from AAC to establish communication with others using their remaining abilities, such as tongue or eye motion. 

\subsection{Voice/Speech Recognition}

Speech recognition can be applied to typing, voice authorization, and remote health monitoring. It is an essential assistive technology for people who need to convert their voice to text to communicate with others through writing via computers, smartphones, and the internet. In general, in the absence of noise and interference, a wearable microphone is the only sensor needed to record human voice accurately, along with readily available commercial or open-source software to recognize it efficiently. For example, in (Sharma, 2012), a speech recognition system integrates a microphone to provide an alternative communication method for people with disabilities. Another speech recognition technology utilizes a throat-attached microphone to detect the throat vibrations and translate them into words after processing. This method can be more accurate than a standard microphone in noisy or outdoor environments. It also finds use in some industrial and military applications. (8, Lee, 2019). 

Well-commercialization of microphones made them widely available, which created an opportunity for voice and speech recognition technologies, as a microphone is an outstanding sensor with high accuracy. A microphone helps people communicate with others by dictation, i.e., first by converting their voice into text and then typing words on a computer. Since keyboards and mouses are not a word recording method for people with a severe physical disability, the Speech Recognition and Synthesis Tool (SRST) introduced in (Sharma, 2012) relies on a microphone for speech recognition. The SRST proposed a chat room to solve the communication difficulties between the blind and the deaf. This chat room includes two software modes: one for "speech to text" designed for a blind to speak words via a microphone and for a deaf to receive them; the other one for "text to speech" designed with an inverse communication direction. The experiment was performed with five pairs of blind and deaf subjects. After training of subjects about the use of the tool, four out of five pairs of subjects could communicate effectively. However, the environment was supposed to be free of noise, which can hinder the feasibility of the proposed system.

A vibration sensor attached to the user's throat can provide more reliable and accurate speech recognition than a microphone that captures a user's voice signal through air conduction when the environment is noisy and windy. In (Yang, 2015) a throat-attached sensor called "self-powered bionic membrane sensor" (BMS) is introduced for anti‚Äêinterference voice recognition. BMS works as a pressure sensor with 51 mV Pa$^-1$ sensitivity to detect throat skin pressure changes while the user is speaking. Afterward, the system translates the recording data into informative words. The sensor's broad frequency range from 0.1 to 3.2 kHz allows it to throat sound with high frequency. The authors run a speech recognition test with the proposed sensor to prove its capability as a sensitive microphone. During the experiment, the subject who wore BMS on his throat spoke in a noisy environment, and it is observed that the proposed BMS successfully recovered the content of the speech. Thanks to their sensitivity, throat-attached sensors can find wide use in communication systems used in a noisy and long-distance environment such as a construction site, battlefield. 

Another throat-attached sensor, a nanoscale crack sensor inspired by spider sensory system, is demonstrated in (Kang, 2014). This bio-inspired sensor has a strain sensitivity with a gauge factor of 2079 at 2\% applied strain, while it has ultra-high vibration sensitivity of 10-nanometer vibration amplitude detection, sufficient to detect throat vibrations for speech recognition. The human experiment was performed with ten subjects who attached the crack sensors on their necks and repeated four words ('go', 'jump', 'shoot', and 'stop') more than ten times in a noisy environment. In a 92dB noisy environment, the crack sensor recording spectrogram remained stable, but that of a standing microphone was noisy. The detection accuracy of the four selected words with the proposed crack sensor is reported as 97.5\% in a noisy environment.

(Lee, 2019) presented a novel vibration-responsive electronic skin for speech recognition. The electronic skin is composed of a flexible ultrathin accelerometer that takes advantage of the linear relationship between voice pressure and skin acceleration. This accelerometer achieves an ultra-high voice sensing sensitivity of 5.5 V Pa$^-1$. This novel device's ultrathin structure eliminates the vibrational distortions and maintains vibration sensitivity higher than 90\% of its ideal sensitivity on the rough and curved throat skin. To test proposed design, the authors implemented a voice authentication test and asked a subject to log in to a PC by pronouncing the passwords. In order to prove the device's counter-noise ability, the subject was also asked to turn on a light via voice in a \sim 62 dB SPL noisy environment. The subject could successfully finish these tasks. The authors alseo investigated the device's performance in voice dosimetry for health monitoring. The researchers recorded voice for four minutes through the device and extracted the acoustic parameters of the subject's voice for vocal health diagnoses.


\subsection{Language Disorders}
People with speech and language disorders are facing difficulty in verbal communication with others and may completely lose their ability to speak in the long term. Speech and language disorders have different types and categories, such as apraxia of speech, dysarthria, and aphasia, which is out of the scope of this chapter. However, it is important to note that there is a difference between people who cannot express their thoughts with coherent words (apraxa of speech) those who have lost the ability to move the muscles involves in speech (dysarthria), and people who have lost their ability to sound after throat surgeries (laryngectomy) or are mute congenitally. The type of therapies, rehabilitation procedures, and assistive technologies that would fit each group may also be different. Many assistive technologies that employ various sensors have been introduced to restore from language disorders and assist people in expressing themselves fluently. Sensors deployed in these technologies play remarkable roles in capturing essential features of speaking, such as tongue's movements and postures, articulatory muscles' electromyography (EMG) changes, and neural activities. The selected literature in this section includes magnetic senosrs, optical distance sensors, surface electromyography (sEMG) sensors, and electrocorticography (ECoG) sensors. We will cover selected salient speech recognition systems and the sensors used in these systems in the following paragraphs.

The tongue has a unique posture for every phoneme during a speech. Thus, accurate information of speaking can be extracted by the movements and the postures of the tongue.(Nordine, 2020) presents a speech restoration device that implements a tongue tracking system, previously introduces in (Nordine,2019), and integrates 24 magnetic sensors. Those magnetic sensors are distributed equally to 6 sensor arrays and fixed around a user's mouth by a headset. A magnet sheet was stuck on the user's tip of the tongue and traced by the magnetic sensors to monitor the tongue's movements and postures. To test this system's accuracy on the application of phoneme landmarks, the research group collected 2500 tongue trajectories from 10 subjects to repeat 25 phonemes by 10 times. The median tracking errors across the tongue trajectories is 3.9 mm and 75\% tracking error is less than 5.8 mm. A language restoration system presented in this paper could guide people with language disorders to have proper tongue placements for phonemes. The next steps of this research include: 1) Finding  a way to place the tracer at the same position. 2) Considering the tongue and oral cavity's dimension. 3) Designing a flexible and convenient headset for free movements of a user's neck with ensured tracking accuracy.

Optopalatography (OPG) is a method that uses optical sensor to track the tongue movement by measuring the distance between the tongue surface and the hard plate inside the oral cavity. (Birkholz, 2015 cite from Stone) introduces a method to calibrate OPG sensors semi-automatically with the assumption of the tongue surface is parallel with the light source. However, this calibration method introduces significant errors when the tongue surface is not perpendicular to the optical sensor axis. (Stone, 2017) solves this problem by creating a light propagation model that setups an arbitrary source-reflector-detector to correct distance errors for OPG sensors. This technique is based on measuring the light intensity at three positions instead of one by OPG sensors. Human test results with five subjects have shown the median value of mean distance error drops from 7.38\% to 2.25\% and the standard deviation of that decreases from 2.79\% to 1.9\%. This study demonstrates a significant improvement in tongue contours sensing accuracy, crucial to develop a system that helps people with language disorder correct their tongue placement based on OPG sensing data. The provision for future research is investigating how OPG sensors could accurately detect every tongue postures for any phonemes.

A method called "silent speech recognition" utilizes articulatory muscles' surface electromyographic (sEMG) signals that transmit the speech information, which helps people's communication after laryngectomy. (Rameau, 2019) demonstrates a speech restoration device based on the measurement of sEMG signals during the speech. sEMG electrodes are placed in a wearable 3D printing mask. Machine leaning algorithms extract informative features from the sEMG signals and translate them into words. This work also presents the results of a human subject's testing. The subject was asked to sound "Tedd" and "Ed" 75 times for each words while seven sEMG electrodes were recording EMG signals. The post-processed sEMG signal with propossed machine learning algorithm demonstrates 86.4\% accuracy. With that result, this paper has proven sEMG sensors' capability in speech recognition applications. However, to translate the proposed silent speech recognition system into a synthesized voice speech application, further subject testing with an increased number of subjects and a complex library of words is necessary.

Unlike the noninvasive sensory system for speech recognition application mentioned above, an invasive electrocorticographic (ECoG) based sensory system called Brain-to-Speech is introduced in (Herff, 2018). This system combines ECoG signals and a person's disordered audio to reconstruct a nearly natural voice. This method aims to create a communication tool for people with severe neurological disorders in the brain. The ECoG signals are filtered with an algorithm to extract informative speech records. People's audio signals are necessary to imitate a user's own voice. Six subjects who had glioma resection were enrolled in the testing. The correlation coefficient between ECoG and reconstructed audio is 0.574 for the best subject and 0.246 on average. 55 healthy subjects participated in another experiment that detects the most likely recognized word among four options while hearing the reconstructed audio. The accuracy achieved is 66.1 ¬± 5.9\% in average. One step further for the development of this technology is the real-time combination of ECoG signals with prerecorded audio of the user before or in the early stage of the neurological disorder. 

\subsection{Sensors in Use}
\subsubsection{Magnetic Sensor}
Magnetic sensors measure the magnetic flux density of environment. (Sebkhi et al., 2019) deployed 24 distributed magnetic sensors to 6 sensor arrays, surrounding the user's month. The magnetic sensor, LSM303D 3-axial magnetometers (STMicroelectronics), has selectable magnetic field dynamic ranges of ¬±2 / ¬±4 / ¬±8 / ¬±12 gauss with a maximum 100 Hz sampling rate. A ¬±4 dynamic range with a resolution of 0.16 mgauss/LSB was selected in the proposed work.

\subsubsection{OPG Sensor}
The OPG sensor is a device that uses an artificial hard palate equipped with optical sensors.  (Stone et al., 2017) integrates a light source and a detector on the proposed OPG sensor that takes advantage of the reflect distance between the tongue plane and the detector to monitor the tongue's postures. 
%The sensor's schematic diagram is included in (Birkholz, 2012 conference). 
The sensor, utilized in (Birkholz, 2012 conference), has five OPG sensors mounted on the user's upper jaw. The light source and the detector used in the proposed work are an infrared emitter LED (OP280V) manufactured by Optek / TT Electronics and a phototransistor (TEMT7100) from Vishay Semiconductor, respectively.

\subsubsection{sEMG Electrode}
sEMG electrodes detect an record the electric activity of groups of muscles at rest and during activity from the skin surface over the muscles. In (Rameau, 2019), sEMG electrodes are employed to detect the EMG signals of the articulatory muscles, which is then used as an input to the application to translate the signals to words. The system deploys five electrodes on different articulatory muscles for recording and two other electrodes on the auricle and the mastoid tip for reference purposes. The The sEMG electrodes utilized in (Rameau, 2019) were disposable, 24 mm Ag/AgCl sEMG electrodes from Covidien, INC. and they were processed through a biosensing board (OpenBCI, INC., NY).

\subsubsection{ECoG Electrode}
ECoG electrodes placed directly on the cortical surface record the electrical activity. In (Herff, 2018), ECoG electrodes are used for collecting ECoG signals while the user speaks. The collected ECoG signals were processed through a filter algorithm that extracts the informative part of the speech records, which is then combined with an audio record to create a reconstructed audio voice for speech disordered patients. This method required to implant 8 x 8, 64 channels ECoG grids on the patients' left hemispheres. The ECoG electrodes grids used in the experiment manufactured by Integra.

\subsubsection{Microphone}
Microphone is commonly used in speech recognition systems, because of its recording accuracy and stability. The assistive technology introduced in (Sharma, 2012) integrated a microphone for.

%Accelerator
\subsubsection{Pressure Sensor}
A pressure sensor used to detect 

%Pressure Sensor
\subsubsection{Crack Sensor}
ECoG electrodes implemented in the paper (Herff, 2018) for collecting ECoG signals during user speaking. The collected ECoG signals were processed through a filter algorithm to get informative speech records and combined with audio record to create reconstructed audio voice for speech disoder patients. This method required to implant 8 x 8, 64 channels ECoG grids on the patients' left hemispheres. The ECoG electrodes grids used by the research team was manufactured by Integra.

%Bio-inspired sensor
\subsubsection{ECoG Electrode}
ECoG electrodes implemented in the paper (Herff, 2018) for collecting ECoG signals during user speaking. The collected ECoG signals were processed through a filter algorithm to get informative speech records and combined with audio record to create reconstructed audio voice for speech disoder patients. This method required to implant 8 x 8, 64 channels ECoG grids on the patients' left hemispheres. The ECoG electrodes grids used by the research team was manufactured by Integra.